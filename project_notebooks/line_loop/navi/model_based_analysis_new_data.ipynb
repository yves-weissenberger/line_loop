{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tricky thing here is the difference between first visits and multiple visits essentially, because the animals have biases \n",
    "\n",
    "\n",
    "You could quantify this with a likelihood based approach. This would be the cleanest. You can calculate under.\n",
    "\n",
    "In effect you don't need them to be making the correct decision at each point, you need them to be more likely to make the correct decision that when they are following a policy that leads them to the correct reward. This could change the results in either direction\n",
    "\n",
    "You could also quantify this as being between having learned the correct policy and not.\n",
    "\n",
    "## Analysing it more complicatedly\n",
    "\n",
    "\n",
    "There are several ways of calculating this. Could compare this to the marginal distribution of all states. Could compare it to the marginal transition matrix.\n",
    "\n",
    "Ok, so the answer here is complicated. What we therefore need to do is quantify the biases. \n",
    "\n",
    "- Quantify stability of biases within session\n",
    "- Quantify the stability of across session biases\n",
    "- Quantify these conditional on reward location\n",
    "\n",
    "My sense is to compare it to the transition matrix distribution calculated for the reward location that preceeded the trial across the entire session\n",
    "\n",
    "\n",
    "## Unaswered questions\n",
    "\n",
    " - What is the null distribution, when you don't directly calculate fraction correct but calculate it against the empirical transition probabilities.\n",
    " - What do you do about transitions where in states that were rewarded??\n",
    " \n",
    " The null hypothesis is that the data\n",
    " \n",
    " \n",
    "Really need to think carefully about how to rule out that this is driven by one step transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import scipy.stats as stt\n",
    "seaborn.set(font_scale=1.5,style='ticks')\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import itertools\n",
    "import functools\n",
    "import networkx as nx\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\yweissenberger\\Documents\\code\\line_loop-master\")\n",
    "sys.path.append(r\"C:\\Users\\yweissenberger\\Documents\\code\\line_loop-master\\packages\")\n",
    "sys.path.append(\"/Users/yves/Documents/Code/line_loop/packages/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mouse_poker as mpk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#physical position of the pokes. In terms of numbering, the pokes are numbered as follows\n",
    "#(or in some cases the indexing starts from 0 rather than 1)\n",
    "\n",
    "\"\"\"\n",
    "     1\n",
    "   2   3\n",
    " 4   5   6 \n",
    "   7   8\n",
    "     9\n",
    "\"\"\"\n",
    "\n",
    "#physical positions of the pokes, used for drawing the graphs\n",
    "#with nodes and edges. The distances here are to scale with\n",
    "#the real thing.\n",
    "poke_pos = [ [149,0],\n",
    "         [68,19],[231,19],\n",
    "       [0,62],[149,62],[298,62],\n",
    "         [68,105],[231,105],\n",
    "              [149,124]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mouse_poker.navi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st_dist(state_seq,pk_ctr,rew_loc):\n",
    "    \"\"\" get distances between current and next state and reward during navigation on the line \"\"\"\n",
    "    \n",
    "    d0 = np.abs(state_seq[pk_ctr]-rew_loc)\n",
    "    d1 = np.abs(state_seq[pk_ctr+1]-rew_loc)\n",
    "    st_dist = state_seq[pk_ctr]-state_seq[pk_ctr+1]\n",
    "    \n",
    "    return d0,d1,st_dist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_changed_with_rew_loc(state_seq,rew_loc,prev_diff_rew_loc):\n",
    "    \n",
    "    if prev_diff_rew_loc!=None:\n",
    "        same_as_prev_pol = (((state_seq[pk_ctr]-rew_loc)>0)==           #direction to reward with location\n",
    "                            ((state_seq[pk_ctr]-prev_diff_rew_loc)>0))  #direction to reward with prev location\n",
    "    else:\n",
    "        same_as_prev_pol = False\n",
    "    \n",
    "    if state_seq[pk_ctr]==prev_diff_rew_loc:\n",
    "        same_as_prev_pol = True\n",
    "    return same_as_prev_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-689-b62b5c24a4fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_nr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlineloop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdat_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevent_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnRews\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rewards_received: {:d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnRews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/line_loop/packages/mouse_poker/load.py\u001b[0m in \u001b[0;36mparse_data\u001b[0;34m(lines, experiment_name)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mtext2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mstate_dict0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'({.*)\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mevent_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'({.*)\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "#f = open(\"/Users/yves/Documents/beh_dat_new_room/line_loop_batch_3NAVI/'460175_10'-2021-03-15-145534.txt\",'r')\n",
    "#f = open(\"/Users/yves/Documents/beh_dat_new_room/line_loop_batch_3NAVI/'460175_10'-2021-03-01-110337.txt\",'r')\n",
    "#f = open(\"/Users/yves/Documents/beh_dat_new_room/line_loop_batch_3NAVI/'456675_10'-2021-02-23-142909.txt\",'r')\n",
    "\n",
    "lines =f.readlines()\n",
    "experiment_name, task_name, subject_id, task_nr, graph,lineloop,date,test,_ = mpk.load.get_metadata(lines)\n",
    "dat_dict,events,event_times,nRews,_ = mpk.load.parse_data(lines,experiment_name)\n",
    "\n",
    "print(\"rewards_received: {:d}\".format(nRews))\n",
    "print('task_nr:{:.0f}'.format(int(task_nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '/Users/yves/Documents/beh_dat_new_room/line_loop_batch_4_RUNNAVI/'\n",
    "allFs = [os.path.join(ROOT,i) for i in os.listdir(ROOT)]\n",
    "allFs = [i for i in allFs if not os.path.isdir(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this extracts the core information from the text file. This is key to work with\n",
    "state_seq, rew_list, port_seq,forced_seq = extract_navi_dat(lines)\n",
    "\n",
    "#this runs the main analysis that we have done so far.\n",
    "#perf,perf_ctr = get_performance(state_seq,rew_list,port_seq,forced_seq,rew_indices,map_poke_to_state,minNrew=0)\n",
    "#fc = perf/perf_ctr  #calculate fraction correct at each point\n",
    "#print(np.nanmean(fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "f = open(allFs[2],'r')\n",
    "lines =f.readlines()\n",
    "state_seq, rew_list, port_seq,forced_seq = extract_navi_dat(lines)\n",
    "print(sum(rew_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False, True, True] False [] 5\n",
      "[False, True, False, True, True] False [] 5\n",
      "[False, True, False, True, True] False [] 5\n",
      "[False, True, False, True, True] False [] 5\n",
      "[False, True, False, True, True] False [] 5\n",
      "[False, True, False, True, True] False [] 5\n",
      "[False, True, False, True, True] False [] 5\n"
     ]
    }
   ],
   "source": [
    "prev_rew_loc = None  #this is the reward location that was last updated\n",
    "direction = None\n",
    "perf = 0\n",
    "trial_ctr = 0\n",
    "has_updated = False\n",
    "\n",
    "\n",
    "rewarded_pokes = np.concatenate([[0],np.where(rew_list)[0]])\n",
    "trial_starts = rewarded_pokes[:-1]\n",
    "trial_ends = rewarded_pokes[1:]\n",
    "rewarded_states = np.concatenate([np.array(state_seq)[trial_starts]])\n",
    "same_as_prev_pol = True\n",
    "exp_dirs = []\n",
    "verbose = True\n",
    "prev_rew_loc = None\n",
    "\n",
    "#this is the start of a \n",
    "for rew_ctr,(st,nd) in enumerate(zip(trial_starts,trial_ends)):\n",
    "\n",
    "    rew_loc = state_seq[nd]  #this is state that is rewarded\n",
    "    #print(state_seq[nd])  #this is the first state the animals enter into\n",
    "    prev_direction = direction\n",
    "    \n",
    "    if rew_loc!=prev_rew_loc:\n",
    "        #print(\"HERE\")\n",
    "        direction = None\n",
    "        has_updated = False\n",
    "        prev_direction = None\n",
    "        exp_dirs = [] #experienced directions\n",
    "        prev_diff_rew_loc = prev_rew_loc\n",
    "    \n",
    "    \n",
    "    direction = (rew_loc - state_seq[st+1])>0 #which side are you approaching the reward from\n",
    "    hasbeenat = []\n",
    "    for pk_ctr in range(st+1,nd):  #for each poke between two rewards  \n",
    "        \n",
    "        d0,d1,st_dist = get_st_dist(state_seq,pk_ctr,rew_loc)\n",
    "        free_choice_trial = forced_seq[pk_ctr]==False\n",
    "        state = state_seq[pk_ctr]\n",
    "        same_as_prev_pol = policy_changed_with_rew_loc(state_seq,rew_loc,prev_diff_rew_loc)\n",
    "        \n",
    "        update_condition_list = [free_choice_trial,                 #NOT a forced trial\n",
    "                                 #prev_diff_rew_loc is not None,    #hash-out if want to look include very first block in session\n",
    "                                 not same_as_prev_pol,              #ensure that this a policy change is required to make correct decision\n",
    "                                 prev_direction is not None,        #make sure NOT looking at first run-to-rew after a block transition (when rew_loc is unknown)\n",
    "                                 direction not in exp_dirs,         #hasn't experienced this direction in this block yet\n",
    "                                 #not has_updated,                  #toggle if only look at first relevant POKE in block\n",
    "                                 state not in hasbeenat\n",
    "                                ]\n",
    "        print(update_condition_list,direction,exp_dirs,rew_loc)\n",
    "        if all(update_condition_list):\n",
    "            if verbose:\n",
    "                print((\"!\"*80 + \"\\n\")*3)\n",
    "\n",
    "\n",
    "            perf += (d1<d0)\n",
    "            trial_ctr += 1\n",
    "\n",
    "            has_updated = True  #if decisions from this block have led to updated\n",
    "\n",
    "        hasbeenat.append(state)\n",
    "    if direction not in exp_dirs:\n",
    "        exp_dirs.append(direction)\n",
    "    prev_rew_loc = rew_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROOT = '/Users/yves/Documents/beh_dat_new_room/line_loop_batch_4_RUNNAVI/'\n",
    "\n",
    "#ROOT = '/Users/yves/Documents/behavior_data/line_loop_cohort_1/line_loop_batch_4_RUNNAVI/'\n",
    "ROOT = '/Users/yves/Documents/beh_dat_new_room/line_loop_batch_3NAVI/'\n",
    "#ROOT = '/Users/yves/Documents/beh_dat_new_room/line_loop_batch_3NAVI_toLOOP//'\n",
    "\n",
    "allFs = [os.path.join(ROOT,i) for i in os.listdir(ROOT)]\n",
    "allFs = [i for i in allFs if not os.path.isdir(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allFs = [i for i in allFs if '460175' in i]\n",
    "allFs = [i for i in allFs if '456675' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks that I have run on this code:\n",
    "\n",
    "- Ensure that distances between states within a trial is always equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions(state_seq,rew_list,forced_seq,minNrew=0,set_rew_indices=None,firstOnly=False):\n",
    "    \"\"\" This function obtains empirical counts for transitions from a given state to another\n",
    "        as a function of \"\"\"\n",
    "    #used_states = sorted([i[1] for i in map_poke_to_state.args[0]])\n",
    "    if set_rew_indices is None: set_rew_indices=list(range(9))\n",
    "    perf = np.zeros([9,9,9])\n",
    "    perf_ctr = np.zeros([9,9,9])\n",
    "    rew_hist = []\n",
    "    transition_mtx = np.zeros([9,9,9])\n",
    "    state_ctr = np.zeros([9,9])\n",
    "    all_rew_loc = []\n",
    "    for rew_ctr,(st,nd) in enumerate(zip(np.where(rew_list)[0][:-2],np.where(rew_list)[0][1:-1])):\n",
    "        #print(1)\n",
    "        rew_loc = state_seq[nd]\n",
    "        if (rew_loc in set_rew_indices):\n",
    "            all_rew_loc.append(rew_loc)\n",
    "            if not rew_hist:\n",
    "                rew_hist.append(rew_loc)\n",
    "            elif rew_loc==rew_hist[-1]:\n",
    "                rew_hist.append(rew_loc)\n",
    "            else:\n",
    "                rew_hist = []\n",
    "\n",
    "            has_visited= []\n",
    "            if len(rew_hist)>minNrew:\n",
    "\n",
    "                for pk_ctr in range(st+1,nd):\n",
    "                    if not forced_seq[pk_ctr]:\n",
    "                        state = state_seq[pk_ctr]\n",
    "                        if state not in has_visited:\n",
    "\n",
    "                            next_state = state_seq[pk_ctr+1]\n",
    "\n",
    "                            transition_mtx[state,next_state,rew_loc] += 1\n",
    "                            state_ctr[state,rew_loc] += 1\n",
    "                            if firstOnly: has_visited.append(state)\n",
    "\n",
    "    \n",
    "    return transition_mtx, state_ctr, np.unique(all_rew_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   4,   6,   9,  11,  18,  24,  26,  37,  44,  49,  59,  62,\n",
       "        65,  69,  76,  92,  95,  98, 104, 106, 111, 147, 155, 164, 167,\n",
       "       169, 171, 176, 181, 188, 194, 199, 201, 203, 206, 208, 212, 215,\n",
       "       217, 220, 224, 228, 230, 233, 236, 238, 266, 268, 270, 279, 282,\n",
       "       289, 291, 296, 298, 301, 330, 347, 363, 366, 369, 372, 378, 388,\n",
       "       415, 418, 420, 435, 441, 456, 459, 464, 466, 468, 470, 472, 474,\n",
       "       483, 486, 490, 492, 501, 503, 506, 508, 513, 547, 581, 587, 589,\n",
       "       602, 608, 610, 612, 614, 618, 622, 626, 628, 630, 633, 637, 641,\n",
       "       643, 645, 647, 649, 651, 681, 692, 694, 699, 702, 704, 706, 711,\n",
       "       716, 718, 723, 725, 730, 734, 746, 748, 751, 754, 758, 760, 764,\n",
       "       768, 773, 808, 820, 823, 827, 832, 835, 838, 848, 853, 856, 859,\n",
       "       861, 869, 871, 873, 878])"
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 1019,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   6,   9,  11,  18,  24,  26,  37,  44,  49,  59,  62,  65,\n",
       "        69,  76,  92,  95,  98, 104, 106, 111, 147, 155, 164, 167, 169,\n",
       "       171, 176, 181, 188, 194, 199, 201, 203, 206, 208, 212, 215, 217,\n",
       "       220, 224, 228, 230, 233, 236, 238, 266, 268, 270, 279, 282, 289,\n",
       "       291, 296, 298, 301, 330, 347, 363, 366, 369, 372, 378, 388, 415,\n",
       "       418, 420, 435, 441, 456, 459, 464, 466, 468, 470, 472, 474, 483,\n",
       "       486, 490, 492, 501, 503, 506, 508, 513, 547, 581, 587, 589, 602,\n",
       "       608, 610, 612, 614, 618, 622, 626, 628, 630, 633, 637, 641, 643,\n",
       "       645, 647, 649, 651, 681, 692, 694, 699, 702, 704, 706, 711, 716,\n",
       "       718, 723, 725, 730, 734, 746, 748, 751, 754, 758, 760, 764, 768,\n",
       "       773, 808, 820, 823, 827, 832, 835, 838, 848, 853, 856, 859, 861,\n",
       "       869, 871, 873, 878, 882])"
      ]
     },
     "execution_count": 1020,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = get_transitions(state_seq,\n",
    "                rew_list,\n",
    "                forced_seq\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9, 9)"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 1023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yves/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/yves/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc9b9bd3250>"
      ]
     },
     "execution_count": 1024,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a[4]/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "state:7,nextstate:6,rew_loc:6,correct:1\n",
      "8 '460175_10'-2021-03-15-145534.txt\n",
      "[6, 7, 6]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "perf = 0\n",
    "trial_ctr = 0\n",
    "\n",
    "check1 = []\n",
    "for fpath in allFs[:3]:\n",
    "\n",
    "    f = open(fpath,'r')\n",
    "    lines =f.readlines()\n",
    "    state_seq, rew_list, port_seq,forced_seq = extract_navi_dat(lines)\n",
    "    prev_rew_loc = None  #this is the reward location that was last updated\n",
    "    direction = None\n",
    "    has_updated = False\n",
    "\n",
    "    rewarded_pokes = np.concatenate([[0],np.where(rew_list)[0]])\n",
    "    trial_starts = rewarded_pokes[:-1]\n",
    "    trial_ends = rewarded_pokes[1:]\n",
    "    rewarded_states = np.concatenate([np.array(state_seq)[trial_starts]])\n",
    "    same_as_prev_pol = True\n",
    "    exp_dirs = []\n",
    "    verbose = True\n",
    "    prev_rew_loc = None\n",
    "\n",
    "    #this is the start of a \n",
    "    for rew_ctr,(st,nd) in enumerate(zip(trial_starts,trial_ends)):\n",
    "\n",
    "        rew_loc = state_seq[nd]  #this is state that is rewarded\n",
    "        #print(state_seq[nd])  #this is the first state the animals enter into\n",
    "        prev_direction = direction\n",
    "\n",
    "        if rew_loc!=prev_rew_loc:\n",
    "            #print(\"HERE\")\n",
    "            direction = None\n",
    "            has_updated = False\n",
    "            prev_direction = None\n",
    "            exp_dirs = [] #experienced directions\n",
    "            prev_diff_rew_loc = prev_rew_loc\n",
    "\n",
    "\n",
    "        direction = (rew_loc - state_seq[st+1])>0 #which side are you approaching the reward from\n",
    "        visited_states = []\n",
    "        #print(state_seq[st],state_seq[st+1])\n",
    "        start_state_trial = state_seq[st+1]\n",
    "        for pk_ctr in range(st+1,nd):  #for each poke between two rewards  \n",
    "\n",
    "            d0,d1,st_dist = get_st_dist(state_seq,pk_ctr,rew_loc)\n",
    "            free_choice_trial = forced_seq[pk_ctr]==False\n",
    "            state = state_seq[pk_ctr]\n",
    "            same_as_prev_pol = policy_changed_with_rew_loc(state_seq,rew_loc,prev_diff_rew_loc)\n",
    "            check1.append(st_dist)\n",
    "            update_condition_list = [free_choice_trial,              #NOT a forced trial\n",
    "                                     prev_diff_rew_loc is None,  #hash-out if want to look include very first block in session\n",
    "                                     not same_as_prev_pol,           #ensure that this a policy change is required to make correct decision\n",
    "                                     prev_direction is not None,     #make sure NOT looking at first run-to-rew after a block transition (when rew_loc is unknown)\n",
    "                                     direction not in exp_dirs,      #hasn't experienced this direction in this block yet\n",
    "                                     #not has_updated,               #toggle if only look at first relevant POKE in block\n",
    "                                     #state not in visited_states,    #look only at first visits to each state\n",
    "                                     #d0>1,\n",
    "                                     #np.abs(start_state_trial-rew_loc)>1,\n",
    "                                     state !=rew_loc\n",
    "                                    ]\n",
    "\n",
    "            #if pk_ctr<60:\n",
    "            #    print(update_condition_list,direction,exp_dirs,state,rew_loc,pk_ctr,os.path.split(fpath)[-1])\n",
    "            if all(update_condition_list):\n",
    "                if verbose:\n",
    "                    print((\"!\"*80 + \"\\n\")*3)\n",
    "                    print('state:{},nextstate:{},rew_loc:{},correct:{}'.format(state,state_seq[pk_ctr+1],rew_loc,int(d1<d0)))\n",
    "                    print(pk_ctr,os.path.split(fpath)[-1])\n",
    "                    print(state_seq[st+1:nd+1])\n",
    "                    print('\\n')\n",
    "\n",
    "                perf += int(d1<d0)\n",
    "                trial_ctr += 1\n",
    "\n",
    "                has_updated = True  #if decisions from this block have led to updated\n",
    "\n",
    "            visited_states.append(state)\n",
    "\n",
    "        if direction not in exp_dirs:\n",
    "            exp_dirs.append(direction)\n",
    "        prev_rew_loc = rew_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in looking at the first block of the session, in a length 6 line, you can only look at rewards that are located\n",
    "#at positions 3 and 4, not at 1 and 2 and not at 5 and 6. Thus you should have 1/3 as many trials as you have sessions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5925925925925926"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf/trial_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_ctr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44206833839416504"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stt.binom_test(perf,trial_ctr,p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
